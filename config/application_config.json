{
    "_comment": "Label Detector Application Configuration - Organized by Service",
    
    "app": {
        "_description": "General application settings",
        "windowMinWidth": 1000,
        "windowMinHeight": 700,
        "jpegQuality": 95,
        "classNames": ["label"],
        "captureDirectory": "output/captures"
    },
    
    "debug": {
        "_description": "Debug and logging settings",
        "enabled": false,
        "basePath": "output/debug",
        "saveCooldown": 2.0,
        "performanceLogging": {
            "enabled": true,
            "logInterval": 1,
            "showInStatusBar": true
        }
    },
    
    "s1_camera": {
        "_description": "Step 1: Camera capture settings",
        "frameWidth": 640,
        "frameHeight": 640,
        "fps": 60,
        "maxCameraSearch": 2
    },
    
    "s2_detection": {
        "_description": "Step 2: YOLO detection settings",
        "backend": "openvino",
        "_comment_backend": "Backend for inference: 'onnx' (ONNX Runtime, cross-platform) or 'openvino' (OpenVINO Runtime, Intel-optimized). Default: 'onnx'",
        "modelPath": "models/yolo11n-seg-version-1-0-0_int8_openvino_model/yolo11n-seg-version-1-0-0.xml",
        "_comment_modelPath_onnx": "For ONNX backend, use: models/yolo11n-seg-version-1-0-0.onnx",
        "_comment_modelPath_openvino": "For OpenVINO backend, use: models/yolo11n-seg-version-1-0-0_int8_openvino_model/yolo11n-seg-version-1-0-0.xml",
        "isSegmentation": true,
        "inputSize": 640,
        "confidenceThreshold": 0.5,
        "maxAreaRatio": 0.40,
        "topNDetections": 2,
        "openvino": {
            "_description": "OpenVINO Runtime performance optimization settings",
            "numThreads": 2,
            "_comment_numThreads": "Number of CPU threads for inference. 0 = use all available cores. Reduce to lower system load.",
            "numStreams": 1,
            "_comment_numStreams": "Number of parallel inference streams. 1 = single stream for low latency. 0 = auto.",
            "performanceHint": "LATENCY",
            "_comment_performanceHint": "Performance mode: 'LATENCY' (single request, low latency) or 'THROUGHPUT' (parallel requests, high throughput).",
            "enableHyperThreading": false,
            "_comment_enableHyperThreading": "Use hyper-threading logical cores. false = use physical cores only for lower latency.",
            "enableCpuPinning": true,
            "_comment_enableCpuPinning": "Pin threads to CPU cores for consistent performance. Disable if running multiple workloads."
        },
        "visualization": {
            "boxColor": [0, 255, 0],
            "textColor": [0, 0, 0],
            "lineThickness": 2,
            "fontSize": 0.8,
            "maskOpacity": 0.4,
            "maskColors": [
                [128, 0, 128],
                [0, 128, 255],
                [255, 0, 0],
                [0, 0, 255],
                [255, 255, 0],
                [255, 0, 255],
                [0, 255, 255],
                [128, 255, 0],
                [255, 128, 0],
                [0, 255, 0]
            ]
        }
    },
    
    "s3_preprocessing": {
        "_description": "Step 3: Document preprocessing - crop, rotate, orientation",
        "enabled": true,
        "forceLandscape": true,
        "aiOrientationFix": true,
        "aiConfidenceThreshold": 0.6,
        "paddleModelPath": "models/paddle/PP-LCNet_x1_0_doc_ori",
        "orientationCpuThreads": 2,
        "_comment_orientationCpuThreads": "Number of CPU threads for orientation classifier. Reduce to lower system load.",
        "orientationEnableMkldnn": true,
        "_comment_orientationEnableMkldnn": "Enable MKL-DNN acceleration for orientation classifier.",
        "displayWidth": 230,
        "displayHeight": 100
    },
    
    "s4_enhancement": {
        "_description": "Step 4: Image enhancement - brightness and sharpness",
        "brightnessEnabled": true,
        "brightnessClipLimit": 2.5,
        "brightnessTileSize": 8,
        "sharpnessEnabled": false,
        "sharpnessSigma": 1.0,
        "sharpnessAmount": 1.5
    },
    
    "s5_qr_detection": {
        "_description": "Step 5: QR code detection",
        "enabled": true,
        
        "backend": "wechat",
        "_comment_backend": "Backend for QR detection: 'zxing' (zxing-cpp, fast) or 'wechat' (OpenCV WeChat QRCode, deep learning). Default: 'zxing'",
        
        "zxing": {
            "_description": "ZXing-cpp backend settings",
            "tryRotate": true,
            "_comment_tryRotate": "Try rotated barcodes (90/270 degrees)",
            "tryDownscale": true,
            "_comment_tryDownscale": "Try downscaled versions for better detection"
        },
        
        "wechat": {
            "_description": "OpenCV WeChat QRCode backend settings",
            "modelDir": "models/wechat",
            "_comment_modelDir": "Directory containing WeChat QR model files (detect.prototxt, detect.caffemodel, sr.prototxt, sr.caffemodel)"
        },
        
        "preprocessing": {
            "_description": "QR image preprocessing settings (applied before detection)",
            
            "enabled": true,
            "_comment_enabled": "Enable/disable preprocessing. When enabled, applies pipeline based on mode.",
            
            "mode": "full",
            "_comment_mode": "Preprocessing mode: 'minimal' (scale only) or 'full' (scale → denoise → binary → morph → invert)",
            
            "scaleFactor": 1.5,
            "_comment_scaleFactor": "Scale image by this factor (used in both modes)"
        }
    },
    
    "s6_component_extraction": {
        "_description": "Step 6: Extract label components relative to QR position",
        "aboveQrWidthRatio": 0.35,
        "aboveQrHeightRatio": 0.18,
        "belowQrWidthRatio": 0.65,
        "belowQrHeightRatio": 0.55,
        "padding": 5,
        "aboveQrScaleFactor": 2.0,
        "_comment_aboveQrScaleFactor": "Scale factor for above-QR region before merging (improves OCR accuracy for small text)"
    },
    
    "s7_ocr": {
        "_description": "Step 7: OCR text extraction using PaddleOCR",
        "enabled": true,
        "lang": "en",
        "useTextlineOrientation": false,
        
        "textDetectionModelName": "PP-OCRv5_mobile_det",
        "textRecognitionModelName": "PP-OCRv5_mobile_rec",
        
        "precision": "fp32",
        "enableMkldnn": true,
        "mkldnnCacheCapacity": 10,
        "cpuThreads": 2,
        
        "textDetLimitType": "max",
        "textDetLimitSideLen": 640,
        "textDetThresh": 0.15,
        "textDetBoxThresh": 0.15,
        "textDetUnclipRatio": 2.0,
        
        "textRecScoreThresh": 0.3,
        "device": "cpu"
    },
    
    "s8_postprocessing": {
        "_description": "Step 8: Text postprocessing - fuzzy matching and validation",
        "minFuzzyScore": 0.90,
        "productsJsonPath": "data/products.json",
        "sizesJsonPath": "data/sizes.json",
        "colorsJsonPath": "data/colors.json"
    }
}
