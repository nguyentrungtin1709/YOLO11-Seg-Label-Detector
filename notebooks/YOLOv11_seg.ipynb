{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8glfHzaDfne"
      },
      "source": [
        "# Check GPU availability\n",
        "Check GPU drivers and CUDA availability for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQSmuyPQAkJN",
        "outputId": "722dd301-f255-41e1-8d28-6397aceb6639"
      },
      "outputs": [],
      "source": [
        "# Check GPU status\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83o88WXQDkFl"
      },
      "source": [
        "# Install required packages\n",
        "Install required packages for downloading dataset and training YOLOv11 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMsUDQ7VClWN",
        "outputId": "6d5eb1de-299f-4d10-d097-1c735f816bed"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "print(\"Installing required packages...\")\n",
        "%pip install -q ultralytics roboflow comet_ml\n",
        "print(\"Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJI4PPkgiWYe",
        "outputId": "093859fa-718b-4fc2-e1e3-91697297ec56"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import userdata\n",
        "import comet_ml\n",
        "\n",
        "# Roboflow configuration\n",
        "ROBOFLOW_API_KEY=userdata.get('ROBOFLOW_API_KEY')\n",
        "ROBOFLOW_WORKSPACE=userdata.get('ROBOFLOW_WORKSPACE')\n",
        "ROBOFLOW_PROJECT=userdata.get('ROBOFLOW_PROJECT')\n",
        "ROBOFLOW_VERSION=userdata.get('ROBOFLOW_VERSION')\n",
        "\n",
        "# Comet ML configuration and initialization\n",
        "COMET_API_KEY=userdata.get('COMET_API_KEY')\n",
        "\n",
        "print(\"Initializing Comet ML...\")\n",
        "comet_ml.login(api_key=COMET_API_KEY, project_name=\"yolo11-instance-segmentation\")\n",
        "print(\"✓ Comet ML initialized successfully!\")\n",
        "print(\"Dashboard URL will be available when training starts.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlOqJ8WgDqNs"
      },
      "source": [
        "# Download dataset from Roboflow\n",
        "Download dataset from Roboflow for YOLOv11 training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK_-HnFGBUcZ",
        "outputId": "94f08c3a-242d-4919-b302-0b8ab88c171a"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "from roboflow import Roboflow\n",
        "\n",
        "print(\"Downloading dataset from Roboflow...\")\n",
        "print(f\"Workspace: {ROBOFLOW_WORKSPACE}\")\n",
        "print(f\"Project: {ROBOFLOW_PROJECT}\")\n",
        "print(f\"Version: {ROBOFLOW_VERSION}\")\n",
        "\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(ROBOFLOW_WORKSPACE).project(ROBOFLOW_PROJECT)\n",
        "version = project.version(int(ROBOFLOW_VERSION))\n",
        "dataset = version.download(\"yolov11\")\n",
        "\n",
        "print(\"Dataset downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju74-EvDBbtY"
      },
      "source": [
        "# Configure TensorBoard (DEPRECATED - Using Comet ML)\n",
        "\n",
        "**NOTE**: TensorBoard code has been replaced with Comet ML for better visualization and collaboration.\n",
        "The code below is kept for reference only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUwSUpKHBhgS",
        "outputId": "aabde246-bdaf-45aa-a4ec-101b991ea7a0"
      },
      "outputs": [],
      "source": [
        "# DEPRECATED: Replaced with Comet ML logging\n",
        "# TensorBoard code is kept below for reference\n",
        "\n",
        "# # Configure TensorBoard for logging\n",
        "# from ultralytics import settings\n",
        "\n",
        "# # Enable TensorBoard in Ultralytics\n",
        "# settings.update({'tensorboard': True})\n",
        "\n",
        "# # Load TensorBoard extension in Colab\n",
        "# %load_ext tensorboard\n",
        "\n",
        "# # Start TensorBoard (will monitor runs/detect directory)\n",
        "# %tensorboard --logdir runs/detect\n",
        "\n",
        "# print(\"TensorBoard is ready! Check the output above to view training metrics.\")\n",
        "\n",
        "print(\"TensorBoard logging has been replaced with Comet ML.\")\n",
        "print(\"Comet ML provides better visualization, cloud-based dashboard, and easier collaboration.\")\n",
        "print(\"The dashboard URL will appear when you start training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32V4m4N4BlSv"
      },
      "source": [
        "# Train YOLO11n-seg Model with Comet ML Logging\n",
        "\n",
        "Fine-tune YOLO11n-seg (Instance Segmentation) on custom dataset with optimized parameters for Tesla T4.\n",
        "Comet ML will automatically log all metrics, hyperparameters, and visualizations.\n",
        "\n",
        "**Note**: Instance segmentation models provide both bounding boxes AND pixel-level masks for each detected object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUDsIqqXBmqO",
        "outputId": "3fac3ffa-4880-4286-8d13-8f941a75cdf8"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Get the data.yaml path from the downloaded dataset\n",
        "data_yaml = f\"{dataset.location}/data.yaml\"\n",
        "print(f\"Dataset location: {data_yaml}\")\n",
        "\n",
        "# Load pretrained YOLO11n-seg model (Instance Segmentation)\n",
        "# This model provides both bounding boxes AND pixel-level masks\n",
        "model = YOLO('yolo11n-seg.pt')\n",
        "print(\"YOLO11n-seg model loaded successfully!\")\n",
        "print(f\"Model type: Instance Segmentation\")\n",
        "print(f\"Model size: {sum(p.numel() for p in model.model.parameters()) / 1e6:.2f}M parameters\")\n",
        "\n",
        "# Train the segmentation model with optimized parameters for Tesla T4\n",
        "# NOTE: Comet ML will automatically log all metrics, hyperparameters, and visualizations\n",
        "# Dashboard URL will appear below when training starts\n",
        "print(\"\\nStarting segmentation training with Comet ML logging...\")\n",
        "print(\"Comet dashboard URL will appear below...\\n\")\n",
        "\n",
        "results = model.train(\n",
        "    # Dataset configuration\n",
        "    data=data_yaml,                     # Path to dataset YAML (must have segmentation annotations)\n",
        "\n",
        "    # Training parameters\n",
        "    epochs=50,                          # Number of epochs\n",
        "    imgsz=640,                          # Image size (640x640)\n",
        "    batch=16,                           # Batch size (optimized for T4 16GB)\n",
        "\n",
        "    # Optimization\n",
        "    device=0,                           # Use GPU\n",
        "    workers=4,                          # Number of dataloader workers\n",
        "\n",
        "    # Learning rate\n",
        "    lr0=0.01,                           # Initial learning rate\n",
        "    lrf=0.01,                           # Final learning rate factor\n",
        "\n",
        "    # Augmentation (YOLO11-seg optimized)\n",
        "    hsv_h=0.015,                        # HSV-Hue augmentation\n",
        "    hsv_s=0.7,                          # HSV-Saturation\n",
        "    hsv_v=0.4,                          # HSV-Value\n",
        "    degrees=0.0,                        # Rotation\n",
        "    translate=0.1,                      # Translation\n",
        "    scale=0.5,                          # Scale\n",
        "    fliplr=0.5,                         # Horizontal flip probability\n",
        "    mosaic=1.0,                         # Mosaic augmentation\n",
        "    copy_paste=0.1,                     # Copy-paste augmentation (good for segmentation)\n",
        "\n",
        "    # Saving and logging\n",
        "    save=True,                          # Save checkpoints\n",
        "    save_period=10,                     # Save every 10 epochs\n",
        "    project='runs/segment',             # Output directory for segmentation\n",
        "    name='yolo11n_seg_product_labels',  # Experiment name\n",
        "    exist_ok=True,                      # Overwrite if exists\n",
        "\n",
        "    # Validation\n",
        "    val=True,                           # Run validation after each epoch\n",
        "\n",
        "    # Visualization\n",
        "    plots=True,                         # Generate plots (including mask visualizations)\n",
        "\n",
        "    # Early stopping\n",
        "    patience=10,                        # Stop if no improvement after 50 epochs\n",
        "\n",
        "    # Mixed precision training (speeds up training on T4)\n",
        "    amp=True,                           # Automatic Mixed Precision\n",
        "\n",
        "    # Segmentation specific\n",
        "    mask_ratio=4,                       # Mask downsample ratio (default=4)\n",
        "    overlap_mask=True,                  # Masks overlap during training (good for dense objects)\n",
        "\n",
        "    # Verbose output\n",
        "    verbose=True                        # Detailed output\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(\"✓ All metrics, visualizations, and model artifacts logged to Comet ML dashboard\")\n",
        "print(f\"Best model saved at: runs/segment/yolo11n_seg_product_labels/weights/best.pt\")\n",
        "print(f\"Last model saved at: runs/segment/yolo11n_seg_product_labels/weights/last.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whVHkXtdBomP"
      },
      "source": [
        "# Model Validation (Segmentation)\n",
        "\n",
        "Evaluate segmentation model performance on validation set.\n",
        "Metrics include both bounding box (box) and mask (seg) metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEQC1ayMBruu"
      },
      "outputs": [],
      "source": [
        "# Load the best trained segmentation model\n",
        "best_model = YOLO('runs/segment/yolo11n_seg_product_labels/weights/best.pt')\n",
        "\n",
        "# Validate the model\n",
        "print(\"Running segmentation validation...\")\n",
        "metrics = best_model.val(data=data_yaml)\n",
        "\n",
        "# Print detailed metrics for both Box and Mask\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SEGMENTATION VALIDATION METRICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Bounding Box Metrics\n",
        "print(\"\\nBOUNDING BOX METRICS:\")\n",
        "print(\"-\"*40)\n",
        "print(f\"mAP50-95 (Box): {metrics.box.map:.4f}\")      # mAP at IoU 0.5:0.95\n",
        "print(f\"mAP50 (Box):    {metrics.box.map50:.4f}\")    # mAP at IoU 0.5\n",
        "print(f\"mAP75 (Box):    {metrics.box.map75:.4f}\")    # mAP at IoU 0.75\n",
        "print(f\"Precision (Box): {metrics.box.mp:.4f}\")      # Mean precision\n",
        "print(f\"Recall (Box):    {metrics.box.mr:.4f}\")      # Mean recall\n",
        "\n",
        "# Segmentation Mask Metrics\n",
        "print(\"\\nSEGMENTATION MASK METRICS:\")\n",
        "print(\"-\"*40)\n",
        "print(f\"mAP50-95 (Mask): {metrics.seg.map:.4f}\")     # mAP at IoU 0.5:0.95 for masks\n",
        "print(f\"mAP50 (Mask):    {metrics.seg.map50:.4f}\")   # mAP at IoU 0.5 for masks\n",
        "print(f\"mAP75 (Mask):    {metrics.seg.map75:.4f}\")   # mAP at IoU 0.75 for masks\n",
        "print(f\"Precision (Mask): {metrics.seg.mp:.4f}\")     # Mean precision for masks\n",
        "print(f\"Recall (Mask):    {metrics.seg.mr:.4f}\")     # Mean recall for masks\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Print per-class metrics if available\n",
        "if hasattr(metrics.box, 'maps') and hasattr(metrics.seg, 'maps'):\n",
        "    print(\"\\nPer-class Metrics:\")\n",
        "    print(f\"{'Class':<15} {'Box mAP50-95':<15} {'Mask mAP50-95':<15}\")\n",
        "    print(\"-\"*45)\n",
        "    for i, (box_map, seg_map) in enumerate(zip(metrics.box.maps, metrics.seg.maps)):\n",
        "        print(f\"Class {i:<9} {box_map:<15.4f} {seg_map:<15.4f}\")\n",
        "\n",
        "print(\"\\n✓ Validation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WamFXATJBuou"
      },
      "source": [
        "# Export Segmentation Model to ONNX\n",
        "\n",
        "Export the segmentation model to ONNX format for flexible deployment.\n",
        "The exported model includes both detection head and segmentation head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRSRqGOuBsp2"
      },
      "outputs": [],
      "source": [
        "# Export the best segmentation model to ONNX format\n",
        "print(\"Exporting segmentation model to ONNX format...\")\n",
        "print(\"This will include both detection and segmentation heads.\")\n",
        "\n",
        "onnx_path = best_model.export(\n",
        "    format='onnx',          # ONNX format\n",
        "    imgsz=640,              # Input size (640x640)\n",
        "    dynamic=False,          # Fixed input size (better for deployment)\n",
        "    simplify=True,          # Optimize the ONNX graph\n",
        "    opset=12,               # ONNX opset version (widely compatible)\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ ONNX export completed!\")\n",
        "print(f\"ONNX model saved at: {onnx_path}\")\n",
        "print(f\"Model is optimized for 640x640 input images\")\n",
        "print(f\"Model type: Instance Segmentation (detection + mask output)\")\n",
        "\n",
        "# Verify the exported ONNX model\n",
        "print(\"\\nVerifying ONNX segmentation model...\")\n",
        "onnx_model = YOLO(onnx_path)\n",
        "print(\"✓ ONNX segmentation model loaded successfully and ready for inference!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlQv4DvAByuO"
      },
      "source": [
        "# Test Segmentation Inference (Optional)\n",
        "\n",
        "Test the segmentation model on sample images from validation set.\n",
        "Results include both bounding boxes and segmentation masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTjdK40JByD3"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Get a sample image from the validation set\n",
        "val_images = glob.glob(f\"{dataset.location}/valid/images/*.jpg\") + \\\n",
        "             glob.glob(f\"{dataset.location}/valid/images/*.png\")\n",
        "\n",
        "if val_images:\n",
        "    # Use the first image as test\n",
        "    test_image = val_images[0]\n",
        "    print(f\"Testing segmentation on: {test_image}\")\n",
        "\n",
        "    # Run segmentation inference with the PyTorch model\n",
        "    print(\"\\nTesting with PyTorch segmentation model...\")\n",
        "    results_pt = best_model(test_image, conf=0.25)\n",
        "\n",
        "    # Save and display results (includes segmentation masks)\n",
        "    results_pt[0].save('inference_pytorch_seg.jpg')\n",
        "    print(\"✓ PyTorch segmentation inference completed\")\n",
        "\n",
        "    # Run inference with the ONNX model\n",
        "    print(\"\\nTesting with ONNX segmentation model...\")\n",
        "    results_onnx = onnx_model(test_image, conf=0.25)\n",
        "    results_onnx[0].save('inference_onnx_seg.jpg')\n",
        "    print(\"✓ ONNX segmentation inference completed\")\n",
        "\n",
        "    # Display segmentation results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SEGMENTATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    result = results_pt[0]\n",
        "\n",
        "    # Display detection info\n",
        "    print(f\"\\nDetected {len(result.boxes)} objects:\")\n",
        "    for i, box in enumerate(result.boxes):\n",
        "        cls_id = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        print(f\"  {i+1}. Class: {result.names[cls_id]}, Confidence: {conf:.2f}\")\n",
        "\n",
        "    # Display mask info if available\n",
        "    if result.masks is not None:\n",
        "        print(f\"\\nSegmentation Masks:\")\n",
        "        print(f\"  - Number of masks: {len(result.masks)}\")\n",
        "        print(f\"  - Mask shape: {result.masks.data.shape}\")\n",
        "\n",
        "        # Access mask data in different formats\n",
        "        masks_data = result.masks.data      # Mask in matrix format (num_objects x H x W)\n",
        "        masks_xy = result.masks.xy          # Mask in polygon format (list of xy coordinates)\n",
        "        masks_xyn = result.masks.xyn        # Normalized polygon coordinates\n",
        "\n",
        "        print(f\"  - Available formats: matrix, polygon (xy), normalized (xyn)\")\n",
        "\n",
        "        # Calculate mask coverage\n",
        "        for j, mask in enumerate(masks_data):\n",
        "            mask_area = mask.sum().item()\n",
        "            total_area = mask.shape[0] * mask.shape[1]\n",
        "            coverage = (mask_area / total_area) * 100\n",
        "            print(f\"  - Mask {j+1} coverage: {coverage:.2f}% of image\")\n",
        "    else:\n",
        "        print(\"\\nNo segmentation masks detected\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Display the image with segmentation\n",
        "    print(\"\\nResult image with segmentation masks:\")\n",
        "    display(Image('inference_pytorch_seg.jpg'))\n",
        "\n",
        "else:\n",
        "    print(\"No validation images found. Please check the dataset path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgwpwQ9BB5Od"
      },
      "source": [
        "# Save Segmentation Models (Optional)\n",
        "\n",
        "Download segmentation models to local machine or save to Google Drive.\n",
        "Includes both PyTorch (.pt) and ONNX formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3O1qmLLB3FF"
      },
      "outputs": [],
      "source": [
        "# Save segmentation models - Upload to Google Drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Check if models exist before copying\n",
        "pytorch_model_path = 'runs/segment/yolo11n_seg_product_labels/weights/best.pt'\n",
        "\n",
        "if not os.path.exists(pytorch_model_path):\n",
        "    print(\"Error: Trained segmentation model not found.\")\n",
        "    print(\"Please run the training cell first.\")\n",
        "elif 'onnx_path' not in globals():\n",
        "    print(\"Error: ONNX model not exported.\")\n",
        "    print(\"Please run the ONNX export cell first.\")\n",
        "else:\n",
        "    # Create a temporary directory for models\n",
        "    models_dir = 'trained_models_seg'\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "    # Copy PyTorch segmentation model\n",
        "    print(\"Copying PyTorch segmentation model...\")\n",
        "    shutil.copy(pytorch_model_path, f'{models_dir}/yolo11n_seg_best.pt')\n",
        "\n",
        "    # Copy ONNX segmentation model\n",
        "    print(\"Copying ONNX segmentation model...\")\n",
        "    shutil.copy(onnx_path, f'{models_dir}/yolo11n_seg_best.onnx')\n",
        "\n",
        "    # Create zip file\n",
        "    print(\"\\nCreating zip archive...\")\n",
        "    zip_filename = 'yolo11n_seg_trained_models'\n",
        "    shutil.make_archive(zip_filename, 'zip', models_dir)\n",
        "    zip_path = f'{zip_filename}.zip'\n",
        "\n",
        "    print(\"\\n✓ Segmentation models packaged successfully!\")\n",
        "    print(f\"Zip file: {zip_path}\")\n",
        "    print(f\"Size: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    # Mount Google Drive\n",
        "    print(\"\\nMounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Copy to Google Drive\n",
        "    drive_path = '/content/drive/MyDrive/yolo11n_seg_trained_models.zip'\n",
        "    print(f\"\\nCopying to Google Drive: {drive_path}\")\n",
        "    shutil.copy(zip_path, drive_path)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SUCCESS! Segmentation models uploaded to Google Drive!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nFile location: MyDrive/yolo11n_seg_trained_models.zip\")\n",
        "    print(f\"Size: {os.path.getsize(drive_path) / (1024*1024):.2f} MB\")\n",
        "    print(f\"Model type: Instance Segmentation (YOLO11n-seg)\")\n",
        "    print(\"\\nYou can now:\")\n",
        "    print(\"  1. Access the file from your Google Drive\")\n",
        "    print(\"  2. Download it from drive.google.com\")\n",
        "    print(\"  3. Share it with others if needed\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Show local file paths as backup\n",
        "    print(f\"\\nLocal backup files:\")\n",
        "    print(f\"  - {os.path.abspath(zip_path)}\")\n",
        "    print(f\"  - {os.path.abspath(models_dir)}/yolo11n_seg_best.pt\")\n",
        "    print(f\"  - {os.path.abspath(models_dir)}/yolo11n_seg_best.onnx\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
