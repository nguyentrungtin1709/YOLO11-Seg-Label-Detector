{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "82a8d0d7",
      "metadata": {
        "id": "82a8d0d7"
      },
      "source": [
        "## 1. Environment Setup\n",
        "Check GPU availability and install necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1aebc02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1aebc02",
        "outputId": "0c026ff3-54c1-4e97-cdaf-3632987116a8"
      },
      "outputs": [],
      "source": [
        "# Check GPU status\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae01f45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eae01f45",
        "outputId": "2d19a76c-0b28-4912-8aec-311e66df97a4"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "print(\"Installing required packages...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Install packages\n",
        "%pip install -q ultralytics roboflow openvino nncf matplotlib seaborn pandas\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff17e82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ff17e82",
        "outputId": "8bd09bc4-c3d6-422d-f0d7-225881d7f919"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Roboflow configuration\n",
        "try:\n",
        "    ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "    ROBOFLOW_WORKSPACE = userdata.get('ROBOFLOW_WORKSPACE')\n",
        "    ROBOFLOW_PROJECT = userdata.get('ROBOFLOW_PROJECT')\n",
        "    ROBOFLOW_VERSION = userdata.get('ROBOFLOW_VERSION')\n",
        "    print(\"✓ Roboflow configuration loaded!\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error loading Roboflow config: {e}\")\n",
        "    print(\"Please ensure you have set up the secrets in Google Colab.\")\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"yolo11n-seg-version-1-0-0\"\n",
        "MODEL_PATH = f\"/content/{MODEL_NAME}.pt\"\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d33b16b",
      "metadata": {
        "id": "2d33b16b"
      },
      "source": [
        "## 2. Download Dataset\n",
        "Download the dataset from Roboflow to be used for INT8 calibration and model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14690cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c14690cc",
        "outputId": "6278b982-4f91-48b8-e95e-d87b1087dcbf"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "print(\"Downloading dataset from Roboflow...\")\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(ROBOFLOW_WORKSPACE).project(ROBOFLOW_PROJECT)\n",
        "version = project.version(int(ROBOFLOW_VERSION))\n",
        "dataset = version.download(\"yolov11\")\n",
        "\n",
        "DATASET_PATH = f\"{dataset.location}/data.yaml\"\n",
        "print(f\"\\n✓ Dataset downloaded to: {dataset.location}\")\n",
        "print(f\"✓ Data YAML: {DATASET_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a84fe6d3",
      "metadata": {
        "id": "a84fe6d3"
      },
      "source": [
        "## 3. Export Models to OpenVINO\n",
        "We will export the PyTorch model to two OpenVINO formats:\n",
        "1.  **FP16 (Half-Precision):** Good balance of speed and accuracy.\n",
        "2.  **INT8 (8-bit Quantization):** Maximum speedup on CPU/iGPU, requires calibration data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1797def3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f99bc004c5c640b5948eb6d7775a9cda",
            "e112c05db3c1470db39fd937b987a35c",
            "3efda05b0f854024902cc053131f9409",
            "57456bdee10d4804863e81b2c72c24e9"
          ]
        },
        "id": "1797def3",
        "outputId": "5c101e53-49c3-4d8c-ae8f-9a0e5f1ac48e"
      },
      "outputs": [],
      "source": [
        "# Load the YOLO11n-seg PyTorch model\n",
        "print(f\"Loading PyTorch model from: {MODEL_PATH}\")\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(\"✓ Model loaded successfully!\")\n",
        "\n",
        "# 1. Export to OpenVINO FP16\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPORTING: OpenVINO FP16\")\n",
        "print(\"=\"*70)\n",
        "fp16_export_path = model.export(\n",
        "    format=\"openvino\",\n",
        "    imgsz=640,\n",
        "    half=True,  # Enable FP16 quantization\n",
        ")\n",
        "print(f\"✓ OpenVINO FP16 model saved to: {fp16_export_path}\")\n",
        "\n",
        "# 2. Export to OpenVINO INT8\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPORTING: OpenVINO INT8\")\n",
        "print(\"=\"*70)\n",
        "print(\"Starting INT8 export with calibration (this may take a while)...\")\n",
        "int8_export_path = model.export(\n",
        "    format=\"openvino\",\n",
        "    imgsz=640,\n",
        "    int8=True,          # Enable INT8 quantization\n",
        "    data=DATASET_PATH,  # Dataset for calibration\n",
        "    fraction=0.5,       # Use 50% of data for calibration\n",
        ")\n",
        "print(f\"✓ OpenVINO INT8 model saved to: {int8_export_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ef391e",
      "metadata": {
        "id": "89ef391e"
      },
      "source": [
        "## 4. Comprehensive Model Evaluation\n",
        "Evaluate all three models (PyTorch, FP16, INT8) on the **Test Dataset** to compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c82bafe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c82bafe",
        "outputId": "96df7d0a-ae37-4861-848d-353230b1598e"
      },
      "outputs": [],
      "source": [
        "# Define model paths\n",
        "models_to_eval = {\n",
        "    'PyTorch': MODEL_PATH,\n",
        "    'OpenVINO_FP16': fp16_export_path,\n",
        "    'OpenVINO_INT8': int8_export_path\n",
        "}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"STARTING COMPREHENSIVE EVALUATION ON TEST DATASET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "all_metrics = {}\n",
        "\n",
        "for name, path in models_to_eval.items():\n",
        "    print(f\"\\nEvaluating: {name}...\")\n",
        "    print(f\"Path: {path}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Load model\n",
        "    eval_model = YOLO(path)\n",
        "\n",
        "    # Run validation on Test set\n",
        "    # Note: For OpenVINO models, we might need to ensure the task is specified if not auto-detected,\n",
        "    # but YOLO class usually handles it.\n",
        "    metrics = eval_model.val(data=DATASET_PATH, split='test', verbose=False)\n",
        "\n",
        "    # Store metrics\n",
        "    all_metrics[name] = {\n",
        "        # Box Metrics\n",
        "        'Box_mAP50-95': metrics.box.map,\n",
        "        'Box_mAP50': metrics.box.map50,\n",
        "        'Box_mAP75': metrics.box.map75,\n",
        "        'Box_Precision': metrics.box.mp,\n",
        "        'Box_Recall': metrics.box.mr,\n",
        "        # Mask Metrics\n",
        "        'Mask_mAP50-95': metrics.seg.map,\n",
        "        'Mask_mAP50': metrics.seg.map50,\n",
        "        'Mask_mAP75': metrics.seg.map75,\n",
        "        'Mask_Precision': metrics.seg.mp,\n",
        "        'Mask_Recall': metrics.seg.mr,\n",
        "    }\n",
        "\n",
        "    print(f\"  ✓ Box mAP50-95:  {metrics.box.map:.4f}\")\n",
        "    print(f\"  ✓ Mask mAP50-95: {metrics.seg.map:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ Evaluation completed for all models!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa9ef56",
      "metadata": {
        "id": "2fa9ef56"
      },
      "source": [
        "## 5. Visualization & Comparison\n",
        "Create high-quality charts to visualize the performance differences between the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1ea64e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "aa1ea64e",
        "outputId": "288a21fc-c349-41f3-f234-c47b679f0394"
      },
      "outputs": [],
      "source": [
        "# Prepare data for plotting\n",
        "metrics_df = pd.DataFrame(all_metrics).T\n",
        "print(\"Metrics Summary:\")\n",
        "display(metrics_df)\n",
        "\n",
        "# Configuration for plot\n",
        "Y_AXIS_MIN = 0.9\n",
        "Y_AXIS_MAX = 1.02\n",
        "# Custom colors for better contrast (Brighter/Nicer): PyTorch (Sky Blue), FP16 (Emerald Green), INT8 (Coral Red)\n",
        "MODEL_COLORS = ['#3498db', '#2ecc71', '#E97F4A']\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Create figure with 2 subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "fig.suptitle('YOLOv11 Segmentation Model Comparison: PyTorch vs OpenVINO (FP16 & INT8)', fontsize=18, fontweight='bold', y=1.05)\n",
        "\n",
        "# Metrics to plot\n",
        "plot_metrics = ['mAP50-95', 'mAP50', 'mAP75', 'Precision', 'Recall']\n",
        "x = np.arange(len(plot_metrics))\n",
        "width = 0.25  # Width of bars\n",
        "\n",
        "# --- Subplot 1: Box Metrics ---\n",
        "ax1 = axes[0]\n",
        "for i, model_name in enumerate(models_to_eval.keys()):\n",
        "    values = [all_metrics[model_name][f'Box_{m}'] for m in plot_metrics]\n",
        "    offset = (i - 1) * width\n",
        "    # Use custom color if available, else default\n",
        "    color = MODEL_COLORS[i] if i < len(MODEL_COLORS) else None\n",
        "    bars = ax1.bar(x + offset, values, width, label=model_name, color=color, edgecolor='black', linewidth=0.5)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax1.annotate(f'{height:.3f}',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3), textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom', fontsize=9, rotation=90)\n",
        "\n",
        "ax1.set_ylabel('Score', fontsize=12)\n",
        "ax1.set_title('Bounding Box Metrics', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(plot_metrics, fontsize=11)\n",
        "ax1.set_ylim(Y_AXIS_MIN, Y_AXIS_MAX)\n",
        "# Move legend to top\n",
        "ax1.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3, framealpha=0.9)\n",
        "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# --- Subplot 2: Mask Metrics ---\n",
        "ax2 = axes[1]\n",
        "for i, model_name in enumerate(models_to_eval.keys()):\n",
        "    values = [all_metrics[model_name][f'Mask_{m}'] for m in plot_metrics]\n",
        "    offset = (i - 1) * width\n",
        "    # Use custom color if available, else default\n",
        "    color = MODEL_COLORS[i] if i < len(MODEL_COLORS) else None\n",
        "    bars = ax2.bar(x + offset, values, width, label=model_name, color=color, edgecolor='black', linewidth=0.5)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax2.annotate(f'{height:.3f}',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3), textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom', fontsize=9, rotation=90)\n",
        "\n",
        "ax2.set_ylabel('Score', fontsize=12)\n",
        "ax2.set_title('Segmentation Mask Metrics', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(plot_metrics, fontsize=11)\n",
        "ax2.set_ylim(Y_AXIS_MIN, Y_AXIS_MAX)\n",
        "# Move legend to top\n",
        "ax2.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3, framealpha=0.9)\n",
        "ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Save chart\n",
        "chart_filename = \"model_comparison_chart.png\"\n",
        "plt.tight_layout()\n",
        "plt.savefig(chart_filename, dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Comparison chart saved to: {chart_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7214162",
      "metadata": {
        "id": "e7214162"
      },
      "source": [
        "## 6. Save Results to Google Drive\n",
        "Archive all artifacts: models, reports, and charts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b00fce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90b00fce",
        "outputId": "5c9c6abb-0700-4a1f-801d-237c42dc0c2c"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directory\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_base_dir = f\"/content/drive/MyDrive/YOLO_Models/{MODEL_NAME}\"\n",
        "output_dir = f\"{output_base_dir}/Summary_{timestamp}\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Save Models\n",
        "print(\"\\n1. Saving Models...\")\n",
        "# PyTorch\n",
        "shutil.copy2(MODEL_PATH, os.path.join(output_dir, f\"{MODEL_NAME}.pt\"))\n",
        "print(f\"   ✓ Saved PyTorch model\")\n",
        "\n",
        "# OpenVINO FP16\n",
        "dest_fp16 = os.path.join(output_dir, \"openvino_fp16\")\n",
        "if os.path.exists(fp16_export_path):\n",
        "    shutil.copytree(fp16_export_path, dest_fp16)\n",
        "    print(f\"   ✓ Saved OpenVINO FP16 model\")\n",
        "\n",
        "# OpenVINO INT8\n",
        "dest_int8 = os.path.join(output_dir, \"openvino_int8\")\n",
        "if os.path.exists(int8_export_path):\n",
        "    shutil.copytree(int8_export_path, dest_int8)\n",
        "    print(f\"   ✓ Saved OpenVINO INT8 model\")\n",
        "\n",
        "# 2. Save Chart\n",
        "print(\"\\n2. Saving Charts...\")\n",
        "shutil.copy2(chart_filename, os.path.join(output_dir, chart_filename))\n",
        "print(f\"   ✓ Saved comparison chart\")\n",
        "\n",
        "# 3. Generate and Save Report\n",
        "print(\"\\n3. Saving Evaluation Report...\")\n",
        "report_file = os.path.join(output_dir, \"evaluation_report.txt\")\n",
        "\n",
        "with open(report_file, 'w') as f:\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(f\"YOLOv11 Segmentation Model Evaluation Report\\n\")\n",
        "    f.write(f\"Model: {MODEL_NAME}\\n\")\n",
        "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"1. MODEL CONFIGURATIONS\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    f.write(f\"PyTorch:       Original FP32\\n\")\n",
        "    f.write(f\"OpenVINO FP16: Half-precision floating point\\n\")\n",
        "    f.write(f\"OpenVINO INT8: 8-bit Integer Quantization (Calibrated on {DATASET_PATH})\\n\\n\")\n",
        "\n",
        "    f.write(\"2. METRICS COMPARISON (TEST DATASET)\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "    # Write table header\n",
        "    headers = [\"Metric\", \"PyTorch\", \"FP16\", \"INT8\", \"Diff(INT8-PT)\"]\n",
        "    f.write(f\"{headers[0]:<20} {headers[1]:<12} {headers[2]:<12} {headers[3]:<12} {headers[4]:<15}\\n\")\n",
        "    f.write(\"-\" * 75 + \"\\n\")\n",
        "\n",
        "    # Write metrics\n",
        "    for metric_key in all_metrics['PyTorch'].keys():\n",
        "        pt_val = all_metrics['PyTorch'][metric_key]\n",
        "        fp16_val = all_metrics['OpenVINO_FP16'][metric_key]\n",
        "        int8_val = all_metrics['OpenVINO_INT8'][metric_key]\n",
        "        diff = int8_val - pt_val\n",
        "\n",
        "        f.write(f\"{metric_key:<20} {pt_val:<12.4f} {fp16_val:<12.4f} {int8_val:<12.4f} {diff:<+15.4f}\\n\")\n",
        "\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"3. DEGRADATION ANALYSIS (INT8 vs PyTorch)\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    box_deg = (all_metrics['OpenVINO_INT8']['Box_mAP50-95'] - all_metrics['PyTorch']['Box_mAP50-95']) / all_metrics['PyTorch']['Box_mAP50-95'] * 100\n",
        "    mask_deg = (all_metrics['OpenVINO_INT8']['Mask_mAP50-95'] - all_metrics['PyTorch']['Mask_mAP50-95']) / all_metrics['PyTorch']['Mask_mAP50-95'] * 100\n",
        "\n",
        "    f.write(f\"Box mAP50-95 Change:  {box_deg:+.2f}%\\n\")\n",
        "    f.write(f\"Mask mAP50-95 Change: {mask_deg:+.2f}%\\n\")\n",
        "\n",
        "print(f\"   ✓ Saved evaluation report\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ ALL TASKS COMPLETED SUCCESSFULLY\")\n",
        "print(f\"Results saved to: {output_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3efda05b0f854024902cc053131f9409": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_57456bdee10d4804863e81b2c72c24e9",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applying Fast Bias correction <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #0068b5; text-decoration-color: #0068b5\">92/92</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:03</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:00</span>\n</pre>\n",
                  "text/plain": "Applying Fast Bias correction \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[38;2;0;104;181m92/92\u001b[0m • \u001b[38;2;0;104;181m0:00:03\u001b[0m • \u001b[38;2;0;104;181m0:00:00\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "57456bdee10d4804863e81b2c72c24e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e112c05db3c1470db39fd937b987a35c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99bc004c5c640b5948eb6d7775a9cda": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e112c05db3c1470db39fd937b987a35c",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Statistics collection <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #0068b5; text-decoration-color: #0068b5\">72/72</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:27</span> • <span style=\"color: #0068b5; text-decoration-color: #0068b5\">0:00:00</span>\n</pre>\n",
                  "text/plain": "Statistics collection \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[38;2;0;104;181m72/72\u001b[0m • \u001b[38;2;0;104;181m0:00:27\u001b[0m • \u001b[38;2;0;104;181m0:00:00\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
